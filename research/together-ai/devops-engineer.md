---
company: together-ai
company_display: Together AI
role: devops-engineer
role_display: DevOps Engineer
role_type: standard
last_updated: 2026-02-23
data_quality: high
salary_data_quarter: 2025-Q4
next_review_due: 2026-05-23
compensation:
  - region: San Francisco
    base_low: 148000
    base_high: 195000
    stock_low: 38000
    stock_high: 60000
    bonus_pct: 10
    total_comp_low: 178000
    total_comp_high: 245000
    currency: USD
  - region: Seattle
    base_low: 141000
    base_high: 185000
    stock_low: 36000
    stock_high: 57000
    bonus_pct: 10
    total_comp_low: 169000
    total_comp_high: 233000
    currency: USD
  - region: Remote US
    base_low: 133000
    base_high: 175000
    stock_low: 34000
    stock_high: 54000
    bonus_pct: 10
    total_comp_low: 160000
    total_comp_high: 220000
    currency: USD
level_mapping:
  internal: null
  raw: Together AI DevOps ≈ Google SRE L4–L5 · Meta Production Engineer IC4 · Amazon DevOps Engineer III · Anthropic Infrastructure Engineer · Apple SRE
data_sources:
  - Levels.fyi
  - Glassdoor
negotiation_dna_summary: "Pre-IPO Equity + Base + Bonus | AI Inference & Optimization | 400% YoY Growth | $3.3B Valuation | +20% Kernel Innovation Premium"
---
### DevOps Engineer | Together AI Global Negotiation Guide

**Negotiation DNA:** Pre-IPO Equity + Base + Bonus | AI Inference & Optimization | 400% YoY Growth | $3.3B Valuation | +20% Kernel Innovation Premium

| Region | Base Salary | Equity (Options/RSU est.) | Bonus | Total Comp |
|--------|-------------|--------------------------|-------|------------|
| San Francisco | $148K–$195K | $38K–$60K | 10–15% | $178K–$245K |
| Seattle | $141K–$185K | $36K–$57K | 10–15% | $169K–$233K |
| Remote US | $133K–$175K | $34K–$54K | 10–15% | $160K–$220K |

**Negotiation DNA**

DevOps Engineers at Together AI build and maintain the infrastructure that deploys Together Kernel — the proprietary inference optimization framework born from FlashAttention — at massive scale across GPU clusters worldwide. Together AI's 400% YoY revenue growth means infrastructure demands are doubling every few months, and you are the engineer who ensures the kernel optimization stack runs reliably, scales seamlessly, and deploys continuously. Your CI/CD pipelines, infrastructure-as-code, and monitoring systems are the scaffolding on which Together AI's $3.3B valuation rests. (Source: Together AI infrastructure blog posts; engineering job descriptions, 2025.)

**Level Mapping:** Together AI DevOps ≈ Google SRE L4–L5 · Meta Production Engineer IC4 · Amazon DevOps Engineer III · Anthropic Infrastructure Engineer · Apple SRE

**Together Kernel — The FlashAttention Premium**

Together AI created FlashAttention — the single most impactful algorithmic optimization in modern AI, used by every major AI lab. Together Kernel is the proprietary inference optimization framework that delivers state-of-the-art speed and efficiency. With 400% YoY revenue growth and a $3.3B valuation, Together AI needs DevOps engineers who can deploy kernel-optimized inference workloads across heterogeneous GPU environments with zero-downtime reliability. As a DevOps Engineer, you deploy and operationalize the optimization layer that makes AI inference fast and cheap everywhere — the foundational infrastructure of AI deployment. This justifies a 20–25% Kernel Innovation premium. Your negotiation leverage: "I build the optimization layer that makes AI inference fast and cheap everywhere — and I'm the one who makes sure it actually runs in production at scale across thousands of GPUs."

**Global Levers**

1. **GPU Infrastructure Expertise:** "DevOps for GPU-native inference infrastructure is fundamentally different from cloud-app DevOps. I manage multi-cluster GPU deployments, kernel-level monitoring, and inference-specific CI/CD — this commands a premium."
2. **Pre-IPO Reliability Equity:** "Infrastructure reliability directly impacts customer trust and revenue. At 400% growth, every minute of downtime costs exponentially more. My equity should reflect that I'm the uptime guarantee."
3. **Scaling Urgency:** "Together AI's infrastructure needs are growing faster than its team. I'll be operating at a scope that would typically require a team of 3–5 at a larger company."
4. **Operational Criticality:** "If Together Kernel doesn't deploy reliably, the product doesn't exist. I'm not support infrastructure — I'm the deployment engine for the core product."

> **Negotiate Up Strategy:** "I want to build the deployment infrastructure for Together Kernel at a critical scaling moment. My competing offer is $235K TC from [AWS/Google Cloud/Datadog]. I'm targeting a base of $190K, equity valued at $58K/year at current 409A, and a 15% bonus target — approximately $242K TC. My accept-at floor is $220K TC. Below that threshold, the pre-IPO risk premium doesn't justify leaving a liquid compensation package. I also want a $20K sign-on bonus and on-call compensation or additional equity for infrastructure pager responsibilities."

**Evidence & Sources**
- Together AI $3.3B valuation and infrastructure scaling challenges (TechCrunch, 2025)
- FlashAttention deployment requirements across GPU architectures (Together AI engineering blog, 2025)
- Levels.fyi DevOps/SRE compensation at AI infrastructure companies (2025–2026)
- Glassdoor infrastructure engineer salary data for growth-stage AI startups (2025–2026)
