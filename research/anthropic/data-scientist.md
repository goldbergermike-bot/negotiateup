---
company: anthropic
company_display: Anthropic
role: data-scientist
role_display: Data Scientist
role_type: standard
last_updated: 2026-02-23
data_quality: medium
salary_data_quarter: 2025-Q4
next_review_due: 2026-05-23
compensation:
  - region: San Francisco
    base_low: 225000
    base_high: 285000
    stock_low: 275000
    stock_high: 475000
    bonus_pct: null
    total_comp_low: 294000
    total_comp_high: 404000
    currency: USD
  - region: Seattle
    base_low: 218000
    base_high: 271000
    stock_low: 275000
    stock_high: 475000
    bonus_pct: null
    total_comp_low: 287000
    total_comp_high: 390000
    currency: USD
  - region: London
    base_low: 171000
    base_high: 217000
    stock_low: 209000
    stock_high: 361000
    bonus_pct: null
    total_comp_low: 223000
    total_comp_high: 307000
    currency: GBP
level_mapping:
  internal: null
  raw: Anthropic Data Scientist = Google L4-L5 DS = Meta IC4-IC5 DS = Amazon DS II-III = Apple ICT3-ICT4 DS
data_sources:
  - Levels.fyi
  - Glassdoor
  - Blind
negotiation_dna_summary: "Base-Heavy ($300K+) + Pre-IPO Equity | AI Safety Pioneer | Safety Premium"
---
### Data Scientist | Anthropic Global Negotiation Guide

**Negotiation DNA:** Base-Heavy ($300K+) + Pre-IPO Equity | AI Safety Pioneer | Safety Premium

| Region | Base Salary | Equity (Pre-IPO/4yr) | Bonus | Total Comp |
|--------|-------------|---------------------|-------|------------|
| San Francisco | $225K-$285K | $275K-$475K | — | $294K-$404K |
| Seattle | $218K-$271K | $275K-$475K | — | $287K-$390K |
| London | £171K-£217K | £209K-£361K | — | £223K-£307K |

**Negotiation DNA**
Data Scientists at Anthropic work at the epicenter of AI safety measurement — building the evaluation frameworks, safety metrics, and capability benchmarks that determine whether Claude is safe enough to deploy. This is not dashboard-building or A/B test analysis; Anthropic's data scientists design the scientific methodology for assessing frontier AI systems against Constitutional AI principles. You'll create metrics that quantify model safety, helpfulness, and honesty — the core attributes that define Claude's character. The role sits at the intersection of empirical research and product impact, with direct influence on which versions of Claude ship and which don't.

**Level Mapping:** Anthropic Data Scientist = Google L4-L5 DS = Meta IC4-IC5 DS = Amazon DS II-III = Apple ICT3-ICT4 DS

**The Safety Premium — $300K+ Base Benchmark**
Anthropic pays the highest base salaries in the AI industry — the "Safety Premium." This isn't charity; it's strategic. Anthropic attracts mission-driven talent who want to build AI safely, and the high base ensures they don't lose candidates to OpenAI's equity-heavy offers. Use Anthropic's base as your benchmark: "Anthropic is offering me $225K-$285K base for comparable work. Your base needs to match or the equity must compensate for the gap." At the senior data scientist level, Anthropic's base approaches $285K — among the highest DS bases in the industry, and significantly above the typical $200K-$250K range at most tech companies. The Safety Premium also provides financial stability during the pre-IPO period — you're not dependent on a liquidity event to earn market-rate compensation. When comparing offers, Anthropic's base sets the benchmark for AI-safety data science compensation.

**Global Levers**
1. **Safety Metrics Expertise:** "Building evaluation frameworks for frontier AI safety is a nascent discipline with very few qualified practitioners. I have direct experience designing metrics for [model robustness/alignment evaluation/capability assessment], which maps precisely to Anthropic's need for rigorous safety measurement. I'm looking for $275K base to reflect this specialized expertise."
2. **Research-Impact Hybrid Role:** "This role combines research methodology with direct product impact — my evaluations determine whether Claude ships. That's unusual scope for a data scientist position, more analogous to a research scientist at DeepMind. I'd like $280K base and $450K equity/4yr to match the research-grade expectations."
3. **Competing Offers in AI Safety:** "I have an offer from Google DeepMind at $260K base / $380K RSU for a similar evaluation role. Anthropic's Constitutional AI framework is more rigorous and more interesting to me, but I need $275K base and $450K equity/4yr to make the move."
4. **Pre-IPO Equity with Evaluation Leverage:** "As someone who literally measures whether Claude is safe enough to deploy, I have an unusually direct line to Anthropic's core value proposition. I'd like the equity to reflect that leverage — $460K/4yr with consideration for additional grants tied to safety milestones."

> **Negotiate Up Strategy:** "I'm passionate about the science of AI safety evaluation — Anthropic is doing this more rigorously than anyone else. I'm currently weighing a Google DeepMind offer at $260K base / $380K RSU and a Meta FAIR offer at $250K base / $350K RSU. Both are liquid equity. For Anthropic, I need $275K base, $450K equity/4yr, and a $50K signing bonus. The $275K base is critical — it reflects the research-grade expectations of this role. My floor is $255K base; below that, the DeepMind liquid equity and research resources are too compelling to leave. I want to define how the world measures AI safety — Anthropic is the right place for that work."

**Evidence & Sources**
- Levels.fyi Anthropic Data Scientist compensation data (2025-2026)
- Glassdoor Anthropic data science salary reports
- Blind verified AI-company data science compensation threads (2025-2026)
