---
company: anthropic
company_display: Anthropic
role: security-engineer
role_display: Security Engineer
role_type: standard
last_updated: 2026-02-23
data_quality: medium
salary_data_quarter: 2025-Q4
next_review_due: 2026-05-23
compensation:
  - region: San Francisco
    base_low: 235000
    base_high: 298000
    stock_low: 300000
    stock_high: 525000
    bonus_pct: null
    total_comp_low: 310000
    total_comp_high: 429000
    currency: USD
  - region: Seattle
    base_low: 228000
    base_high: 283000
    stock_low: 300000
    stock_high: 525000
    bonus_pct: null
    total_comp_low: 303000
    total_comp_high: 414000
    currency: USD
  - region: London
    base_low: 179000
    base_high: 227000
    stock_low: 228000
    stock_high: 399000
    bonus_pct: null
    total_comp_low: 236000
    total_comp_high: 327000
    currency: GBP
level_mapping:
  internal: null
  raw: Anthropic Security Engineer = Google L5 Security = Meta Security IC5 = Amazon Security Engineer III = Microsoft Senior Security Engineer
data_sources:
  - Levels.fyi
  - Glassdoor
  - Blind
negotiation_dna_summary: "Base-Heavy ($300K+) + Pre-IPO Equity | AI Safety Pioneer | Safety Premium"
---
### Security Engineer | Anthropic Global Negotiation Guide

**Negotiation DNA:** Base-Heavy ($300K+) + Pre-IPO Equity | AI Safety Pioneer | Safety Premium

| Region | Base Salary | Equity (Pre-IPO/4yr) | Bonus | Total Comp |
|--------|-------------|---------------------|-------|------------|
| San Francisco | $235K-$298K | $300K-$525K | — | $310K-$429K |
| Seattle | $228K-$283K | $300K-$525K | — | $303K-$414K |
| London | £179K-£227K | £228K-£399K | — | £236K-£327K |

**Negotiation DNA**
Security Engineers at Anthropic defend one of the most valuable and targeted AI systems in the world. This goes far beyond traditional application security: you'll work on AI model security (prompt injection defense, jailbreak prevention, adversarial robustness), infrastructure security for GPU clusters and training pipelines, and enterprise security for Claude's API and deployment ecosystem. Anthropic's Constitutional AI approach creates unique security challenges — ensuring that safety guardrails can't be bypassed, that model outputs remain within policy boundaries, and that enterprise customers can trust Claude with sensitive data. The intersection of AI safety and cybersecurity is a nascent field, and Anthropic security engineers are literally defining the discipline.

**Level Mapping:** Anthropic Security Engineer = Google L5 Security = Meta Security IC5 = Amazon Security Engineer III = Microsoft Senior Security Engineer

**The Safety Premium — $300K+ Base Benchmark**
Anthropic pays the highest base salaries in the AI industry — the "Safety Premium." This isn't charity; it's strategic. Anthropic attracts mission-driven talent who want to build AI safely, and the high base ensures they don't lose candidates to OpenAI's equity-heavy offers. Use Anthropic's base as your benchmark: "Anthropic is offering me $235K-$298K base for comparable work. Your base needs to match or the equity must compensate for the gap." Security engineers at the senior level can push past $290K base — approaching the $300K threshold that Anthropic is known for. The Safety Premium also provides financial stability during the pre-IPO period — you're not dependent on a liquidity event to earn market-rate compensation. When comparing offers, Anthropic's security engineering base is the benchmark for all AI-company security negotiations.

**Global Levers**
1. **AI Security Specialization Premium:** "Engineers who understand both traditional cybersecurity and AI-specific threats — prompt injection, model extraction, adversarial examples, jailbreaking — are among the rarest talent in the industry. My experience in [AI red-teaming / model security / adversarial ML] directly maps to Anthropic's unique threat landscape. I'm looking for $295K base."
2. **Enterprise Trust Enablement:** "Claude's enterprise adoption depends on security — every Fortune 500 customer evaluates Anthropic's security posture before signing a contract. My work directly enables revenue growth by building the security infrastructure that enterprises require. I'd like $290K base and $510K equity/4yr."
3. **Competing AI Security Offers:** "OpenAI is offering me $270K base / $600K equity for a similar AI security role. Google DeepMind is at $280K base / $420K RSU. Anthropic's Constitutional AI framework creates the most interesting security challenges in the industry, but I need $293K base and $500K equity/4yr to make the total comp competitive."
4. **Threat Landscape Complexity Premium:** "Anthropic faces a unique threat matrix — nation-state adversaries targeting model weights, sophisticated prompt injection attacks, enterprise data privacy requirements, and the novel challenge of securing AI systems that can be manipulated through natural language. This is not standard security engineering. A $60K signing bonus reflects the specialized expertise required."

> **Negotiate Up Strategy:** "I'm drawn to Anthropic because AI model security is the most important and least understood security domain in technology today — and Anthropic is the company taking it most seriously. I'm holding an OpenAI offer at $270K base / $600K equity and a Google DeepMind offer at $280K base / $420K RSU. For Anthropic, I need $293K base, $500K equity/4yr, and a $60K signing bonus. The base is my priority — at $293K, I'm ready to sign. My floor is $270K base; below that, the OpenAI equity and Google liquid RSUs are financially superior. I want to build the security foundations for the AI safety leader — help me get there."

**Evidence & Sources**
- Levels.fyi AI-company security engineer compensation data (2025-2026)
- Glassdoor Anthropic security role salary reports
- Blind verified AI security engineer compensation and offer threads
