### Security Engineer | Amplitude Global Negotiation Guide

**Negotiation DNA:** RSU-Based / Public Company | AI-Powered Product Analytics

| Region | Base Salary | Stock (RSU/4yr) | Bonus | Total Comp |
|--------|-------------|-----------------|-------|------------|
| San Francisco | $165K–$208K | $120K–$205K | 10–15% | $205K–$278K |
| New York | $160K–$203K | $115K–$198K | 10–15% | $200K–$270K |
| London | £100K–£135K | £60K–£108K | 10–15% | £125K–£172K |

**Negotiation DNA**

Security engineers at Amplitude protect a platform that stores behavioral data for some of the world's largest companies. This data — user events, behavioral patterns, product usage — is commercially sensitive and subject to privacy regulations (GDPR, CCPA, and increasingly AI-specific data regulations). A data breach at Amplitude wouldn't just expose user data; it would expose the product strategies and user behavior patterns of Amplitude's enterprise customers. The competitive intelligence contained in Amplitude's data makes it a high-value target.

Amplitude's enterprise customers (Fortune 500 companies, financial services, healthcare) require robust security posture as a condition of vendor selection. Security engineers who can both protect the platform and communicate its security practices to enterprise procurement teams serve a dual purpose — security engineering and sales enablement. SOC 2 Type II, GDPR compliance, and enterprise security reviews are ongoing requirements. [Source: Amplitude Security & Compliance Team 2025-2026]

**Level Mapping:** Amplitude Security (Mid) = Google L4 Security = Meta E4 Security = Mixpanel L3 Security

### AI Data Security Lever

Amplitude's AI features introduce data security challenges: AI models trained on customer behavioral data raise questions about data isolation (can insights from Company A's data leak into Company B's AI results?), model privacy (are individual user behaviors identifiable from model outputs?), and AI governance (how are AI models audited for bias and accuracy?). Security engineers who understand AI-specific data risks are the newest specialty Amplitude needs.

If you bring data privacy expertise alongside application security skills, especially in the context of AI/ML systems, you're addressing Amplitude's most pressing security evolution.

**Global Levers**

1. **Enterprise Customer Trust:** "Enterprise customers require robust security as a vendor selection condition. I both protect the platform and communicate its security posture — serving security and sales enablement."
2. **Competitive Intelligence Data Protection:** "Amplitude stores behavioral data that reveals product strategies. The competitive intelligence value of this data makes it a high-value target — and I'm the engineer preventing that scenario."
3. **AI Data Isolation Security:** "Amplitude's AI features raise data isolation questions: can one customer's data influence another's AI results? I design the isolation architecture that ensures multi-tenant AI safety."
4. **Privacy Regulation Expertise:** "I manage compliance with GDPR, CCPA, and emerging AI data regulations. This evolving regulatory landscape requires continuous security adaptation."

> **Negotiate Up Strategy:** "I'd like the RSU grant at $190K over 4 years with a $22K signing bonus. I protect the behavioral data of Amplitude's enterprise customers while designing AI data isolation architecture. This dual security-plus-AI expertise is essential for enterprise trust." Amplitude will counter at $148K-$178K RSUs — accept at $165K+ with the signing bonus.

#### Evidence & Sources
- [Amplitude Security Engineer Compensation — Levels.fyi 2025-2026]
- [Analytics Platform Security — Enterprise Benchmarks 2026]
- [AI Data Security — Multi-Tenant Model Isolation Trends]
- [Amplitude SOC 2 & GDPR — Trust & Compliance Center]
