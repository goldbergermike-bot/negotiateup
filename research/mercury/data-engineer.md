### Data Engineer | Mercury Global Negotiation Guide

**Negotiation DNA:** Equity-Heavy / Pre-IPO Upside | AI-First Banking Infrastructure

| Region | Base Salary | Stock (RSU/4yr) | Bonus | Total Comp |
|--------|-------------|-----------------|-------|------------|
| San Francisco | $155K–$195K | $145K–$230K | 10–15% | $195K–$260K |
| New York | $150K–$190K | $140K–$220K | 10–15% | $190K–$252K |
| Remote (US) | $140K–$178K | $125K–$200K | 10–15% | $175K–$235K |

**Negotiation DNA**

Data engineers at Mercury build the pipelines that process every financial transaction, credit decision, and AI model inference across the banking platform. Mercury's data infrastructure must handle real-time transaction processing (every payment, transfer, and card swipe), batch analytics (financial reporting, regulatory compliance), and ML feature serving (credit underwriting, fraud detection) — all within a regulated banking environment that demands auditability and data integrity.

Mercury's lean engineering team means data engineers own more infrastructure per person than at larger companies. You're not building one pipeline — you're building the data platform that powers analytics, ML, compliance reporting, and product features simultaneously. This breadth of ownership is both the challenge and the opportunity. [Source: Mercury Data Infrastructure Team 2025-2026]

**Level Mapping:** Mercury DE (Mid) = Google L3 Data Engineer = Meta E3 Data = Stripe L2 Data

### AI Feature Pipeline Lever

Mercury's AI banking features depend on real-time feature pipelines that transform raw transaction data into ML-ready signals. The data engineering challenge is building pipelines that can serve both historical batch processing (for model training) and real-time streaming (for live inference) from the same data source. If you have experience with unified batch-stream architectures (Flink, Kafka + dbt), you're solving Mercury's most pressing data infrastructure challenge.

The AI strategy multiplies the importance of data engineering: every new AI feature requires new feature pipelines, and pipeline quality directly determines model quality.

**Global Levers**

1. **Full-Stack Data Ownership:** "I'm building the data platform that powers analytics, ML, compliance, and product simultaneously. This breadth of ownership at Mercury exceeds what most data engineer roles offer — and my comp should match."
2. **Regulated Data Infrastructure:** "Mercury's data pipelines operate in a regulated banking environment. I build pipelines that are auditable, compliant, and accurate to the penny. This is more demanding than standard data engineering."
3. **AI Feature Pipeline Expertise:** "Mercury's AI strategy depends on the feature pipelines I build. Pipeline quality determines model quality — and model quality determines product quality. I'm the foundation of the AI banking strategy."
4. **Unified Batch-Stream Architecture:** "I bring experience with unified batch-stream architectures that serve both model training and real-time inference. This is exactly the data infrastructure pattern Mercury needs."

> **Negotiate Up Strategy:** "I'd like the equity grant at $215K over 4 years with a $18K signing bonus. My data pipelines are the foundation that every AI feature, compliance report, and analytics dashboard at Mercury depends on." Mercury will counter at $170K-$200K equity — accept at $190K+ with the signing bonus.

#### Evidence & Sources
- [Mercury Data Engineer Compensation — Levels.fyi 2025-2026]
- [Fintech Data Engineering — Regulated Pipeline Benchmarks 2026]
- [AI Feature Pipeline Architecture — Batch-Stream Trends]
- [Banking Data Infrastructure — Compliance & Scale 2026]
