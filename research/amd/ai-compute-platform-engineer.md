### AI Compute Platform Engineer | AMD Global Negotiation Guide

**Negotiation DNA:** Equity-Heavy + Bonus | Semiconductor & AI Compute | AI-Native Workflow | **SIGNATURE ROLE** | **+30% AI PRODUCTIVITY PREMIUM** | **+25–35% AI COMPUTE PREMIUM**

| Region | Base Salary | Stock (RSU/4yr) | Bonus | Total Comp |
|--------|-------------|-----------------|-------|------------|
| Santa Clara | $228K–$282K | $202K–$358K | 15–20% | $302K–$422K |
| Austin | $222K–$275K | $202K–$358K | 15–20% | $295K–$415K |
| Remote US | $215K–$268K | $202K–$358K | 15–20% | $288K–$408K |

**Negotiation DNA**

This is AMD's signature role for 2026 — the AI Compute Platform Engineer. You build the full-stack platform that makes AMD's MI300X/MI400 AI accelerators competitive with NVIDIA — the ROCm AI framework, GPU compiler optimizations, AI model deployment pipelines, multi-GPU scaling infrastructure, and the system software that determines whether the world's largest AI workloads run on AMD or NVIDIA hardware. AMD's AI GPU revenue grew from near-zero to $5B+ in two years, and your platform engineering determines the next $20B+. The dual premium applies: 30% AI-native productivity plus 25-35% AI compute platform scarcity. [Source: AMD AI Compute Platform Team 2026]

**Level Mapping:** AMD AI Compute Platform Eng (PMTS) = NVIDIA CUDA Platform Eng = Intel oneAPI Eng = Google TPU Platform Eng

**What Makes This Role Unique**

The AI Compute Platform Engineer works at the intersection of GPU silicon, AI software frameworks, and data center infrastructure:
- **ROCm AI Framework:** The core software platform that enables AI training and inference on AMD GPUs — competing directly with NVIDIA's CUDA ecosystem
- **GPU Compiler ML Optimization:** ML-driven compiler optimizations that automatically tune generated code for AMD hardware — the most impactful lever on benchmark performance
- **Multi-GPU Scaling:** The distributed computing infrastructure that enables AI training across thousands of MI300X/MI400 GPUs — the scaling that determines whether AMD wins hyperscaler deployments
- **AI Model Deployment Pipeline:** The end-to-end pipeline from model training to production inference deployment on AMD hardware — making AMD the easiest platform for AI developers
- **Hardware-Software Co-Design:** The tight integration between silicon architecture and software optimization — using silicon features to accelerate AI workloads in ways that general-purpose approaches can't

**AI-Native Productivity — The 30% Premium Script**

AMD engineers work with an AI-Native workflow — using AI-assisted development tools, automated code generation, AI-powered testing, and machine-learning-driven optimization across every stage of the development lifecycle. "As the AI Compute Platform Engineer — AMD's signature role — I get the maximum dual premium: 30% AI-native productivity and 25-35% AI compute platform scarcity. I build the full-stack platform that determines whether AMD captures $20B+ in AI compute revenue, and I do it at 1.3x velocity. My AI-native workflow means faster ROCm development, automated performance regression detection, and ML-driven compiler optimization. The script: 'I'm AMD's signature AI role — building the full-stack platform competing with NVIDIA's CUDA. I deliver 1.3x output through AI-native workflows on the most consequential AI compute engineering in the industry. The dual premium of 30% productivity + 30% AI compute scarcity means my comp should be 60%+ above standard semiconductor bands. Engineers who can build competitive AI compute platforms at this level are the scarcest talent in technology — fewer than 500 people worldwide have this expertise.'"

**Global Levers**

1. **Dual Premium — Maximum AI Compute Comp:** "I deliver 1.3x output on the most consequential AI platform engineering in semiconductors. The 30% productivity + 30% AI compute scarcity means maximum RSU allocation — $350K+ over 4 years."
2. **NVIDIA CUDA Platform Parity:** "I build the platform competing with NVIDIA's CUDA — the most valuable software ecosystem in AI. NVIDIA CUDA platform engineers earn $450K+ TC. AMD must match to attract this talent."
3. **$5B to $20B+ Revenue Platform:** "My platform engineering enabled AMD's $5B+ AI revenue and will determine the next $20B+. Every architectural decision I make directly converts to billion-dollar revenue outcomes."
4. **500-Person Global Talent Pool:** "Fewer than 500 engineers worldwide can build competitive AI compute platforms at this level. This extreme scarcity justifies compensation that ignores standard semiconductor bands entirely."

> **Negotiate Up Strategy:** "I'm targeting $278K base with the dual premium (30% productivity + 30% AI compute scarcity) and $352K RSUs over 4 years for this AI Compute Platform Engineer role — AMD's signature position. I build the full-stack AI platform competing with NVIDIA's CUDA — the most consequential AI compute engineering in the industry — at 1.3x velocity. My platform determines whether AMD captures $20B+ in AI revenue. I have competing offers from [NVIDIA at $448K TC / Google at $435K TC / Broadcom at $402K TC]. AMD's AI future depends on this role. Fewer than 500 people can do it." Accept at $258K+ base and $318K+ RSUs.

**Evidence & Sources**
- [AMD AI-Native Workflow — 30% Productivity Premium]
- [AMD AI Compute Platform — Signature Initiative 2026]
- [AMD ROCm vs NVIDIA CUDA — AI Platform Competition]
- [AMD $5B+ AI Revenue — Platform Engineering Impact]
- [AMD MI300X/MI400 — Full-Stack AI Compute Architecture]
